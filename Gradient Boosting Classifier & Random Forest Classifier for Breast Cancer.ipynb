{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original data\n",
      "\n",
      "        0      1       2       3        4        5        6        7       8   \\\n",
      "0   17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
      "1   20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
      "2   19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
      "3   11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
      "4   20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
      "5   12.45  15.70   82.57   477.1  0.12780  0.17000  0.15780  0.08089  0.2087   \n",
      "6   18.25  19.98  119.60  1040.0  0.09463  0.10900  0.11270  0.07400  0.1794   \n",
      "7   13.71  20.83   90.20   577.9  0.11890  0.16450  0.09366  0.05985  0.2196   \n",
      "8   13.00  21.82   87.50   519.8  0.12730  0.19320  0.18590  0.09353  0.2350   \n",
      "9   12.46  24.04   83.97   475.9  0.11860  0.23960  0.22730  0.08543  0.2030   \n",
      "10  16.02  23.24  102.70   797.8  0.08206  0.06669  0.03299  0.03323  0.1528   \n",
      "11  15.78  17.89  103.60   781.0  0.09710  0.12920  0.09954  0.06606  0.1842   \n",
      "12  19.17  24.80  132.40  1123.0  0.09740  0.24580  0.20650  0.11180  0.2397   \n",
      "13  15.85  23.95  103.70   782.7  0.08401  0.10020  0.09938  0.05364  0.1847   \n",
      "14  13.73  22.61   93.60   578.3  0.11310  0.22930  0.21280  0.08025  0.2069   \n",
      "15  14.54  27.54   96.73   658.8  0.11390  0.15950  0.16390  0.07364  0.2303   \n",
      "16  14.68  20.13   94.74   684.5  0.09867  0.07200  0.07395  0.05259  0.1586   \n",
      "17  16.13  20.68  108.10   798.8  0.11700  0.20220  0.17220  0.10280  0.2164   \n",
      "18  19.81  22.15  130.00  1260.0  0.09831  0.10270  0.14790  0.09498  0.1582   \n",
      "19  13.54  14.36   87.46   566.3  0.09779  0.08129  0.06664  0.04781  0.1885   \n",
      "\n",
      "         9   ...     20     21      22      23      24      25      26  \\\n",
      "0   0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
      "1   0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
      "2   0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
      "3   0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
      "4   0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
      "5   0.07613  ...  15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355   \n",
      "6   0.05742  ...  22.88  27.66  153.20  1606.0  0.1442  0.2576  0.3784   \n",
      "7   0.07451  ...  17.06  28.14  110.60   897.0  0.1654  0.3682  0.2678   \n",
      "8   0.07389  ...  15.49  30.73  106.20   739.3  0.1703  0.5401  0.5390   \n",
      "9   0.08243  ...  15.09  40.68   97.65   711.4  0.1853  1.0580  1.1050   \n",
      "10  0.05697  ...  19.19  33.88  123.80  1150.0  0.1181  0.1551  0.1459   \n",
      "11  0.06082  ...  20.42  27.28  136.50  1299.0  0.1396  0.5609  0.3965   \n",
      "12  0.07800  ...  20.96  29.94  151.70  1332.0  0.1037  0.3903  0.3639   \n",
      "13  0.05338  ...  16.84  27.66  112.00   876.5  0.1131  0.1924  0.2322   \n",
      "14  0.07682  ...  15.03  32.01  108.80   697.7  0.1651  0.7725  0.6943   \n",
      "15  0.07077  ...  17.46  37.13  124.10   943.2  0.1678  0.6577  0.7026   \n",
      "16  0.05922  ...  19.07  30.88  123.40  1138.0  0.1464  0.1871  0.2914   \n",
      "17  0.07356  ...  20.96  31.48  136.80  1315.0  0.1789  0.4233  0.4784   \n",
      "18  0.05395  ...  27.32  30.88  186.80  2398.0  0.1512  0.3150  0.5372   \n",
      "19  0.05766  ...  15.11  19.26   99.70   711.2  0.1440  0.1773  0.2390   \n",
      "\n",
      "         27      28       29  \n",
      "0   0.26540  0.4601  0.11890  \n",
      "1   0.18600  0.2750  0.08902  \n",
      "2   0.24300  0.3613  0.08758  \n",
      "3   0.25750  0.6638  0.17300  \n",
      "4   0.16250  0.2364  0.07678  \n",
      "5   0.17410  0.3985  0.12440  \n",
      "6   0.19320  0.3063  0.08368  \n",
      "7   0.15560  0.3196  0.11510  \n",
      "8   0.20600  0.4378  0.10720  \n",
      "9   0.22100  0.4366  0.20750  \n",
      "10  0.09975  0.2948  0.08452  \n",
      "11  0.18100  0.3792  0.10480  \n",
      "12  0.17670  0.3176  0.10230  \n",
      "13  0.11190  0.2809  0.06287  \n",
      "14  0.22080  0.3596  0.14310  \n",
      "15  0.17120  0.4218  0.13410  \n",
      "16  0.16090  0.3029  0.08216  \n",
      "17  0.20730  0.3706  0.11420  \n",
      "18  0.23880  0.2768  0.07615  \n",
      "19  0.12880  0.2977  0.07259  \n",
      "\n",
      "[20 rows x 30 columns]\n",
      "After vectorized train data\n",
      "\n",
      " [[1.917e+01 2.480e+01 1.324e+02 ... 1.767e-01 3.176e-01 1.023e-01]\n",
      " [1.578e+01 2.291e+01 1.057e+02 ... 2.034e-01 3.274e-01 1.252e-01]\n",
      " [7.729e+00 2.549e+01 4.798e+01 ... 0.000e+00 3.058e-01 9.938e-02]\n",
      " ...\n",
      " [1.760e+01 2.333e+01 1.190e+02 ... 1.996e-01 2.301e-01 1.224e-01]\n",
      " [1.403e+01 2.125e+01 8.979e+01 ... 7.963e-02 2.226e-01 7.617e-02]\n",
      " [1.324e+01 2.013e+01 8.687e+01 ... 1.357e-01 2.845e-01 1.249e-01]] \n",
      "\n",
      " [0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0\n",
      " 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1]\n",
      "After vectorized test data\n",
      "\n",
      " [[1.340e+01 2.052e+01 8.864e+01 ... 2.051e-01 3.585e-01 1.109e-01]\n",
      " [1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " ...\n",
      " [2.018e+01 1.954e+01 1.338e+02 ... 2.173e-01 3.032e-01 8.075e-02]\n",
      " [1.831e+01 2.058e+01 1.208e+02 ... 1.510e-01 3.074e-01 7.863e-02]\n",
      " [1.504e+01 1.674e+01 9.873e+01 ... 1.018e-01 2.177e-01 8.549e-02]]\n",
      "\n",
      " Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94        47\n",
      "           1       0.93      1.00      0.96        67\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "\n",
      "Accuracy of the testing dataset :  95.6140350877193\n",
      "Accuracy of the training dataset:  94.5054945054945\n",
      "Accuracy of the validation dataset:  100.0\n",
      "Empty DataFrame\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, y_pred, y_test]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "         0      1       2      3        4        5        6        7       8  \\\n",
      "20   11.84  18.70   77.93  440.6  0.11090  0.15160  0.12180  0.05182  0.2301   \n",
      "40   15.13  29.81   96.71  719.5  0.08320  0.04605  0.04686  0.02739  0.1852   \n",
      "42   16.02  23.24  102.70  797.8  0.08206  0.06669  0.03299  0.03323  0.1528   \n",
      "91   15.12  16.68   98.78  716.6  0.08876  0.09588  0.07550  0.04079  0.1594   \n",
      "108  15.61  19.38  100.00  758.6  0.07840  0.05616  0.04209  0.02847  0.1547   \n",
      "\n",
      "           9  ...     22      23      24       25      26       27      28  \\\n",
      "20   0.07799  ...  119.4   888.7  0.1637  0.57750  0.6956  0.15460  0.4761   \n",
      "40   0.05294  ...  110.1   931.4  0.1148  0.09866  0.1547  0.06575  0.3233   \n",
      "42   0.05697  ...  123.8  1150.0  0.1181  0.15510  0.1459  0.09975  0.2948   \n",
      "91   0.05986  ...  117.7   989.5  0.1491  0.33310  0.3327  0.12520  0.3415   \n",
      "108  0.05443  ...  115.9   988.6  0.1084  0.18070  0.2260  0.08568  0.2683   \n",
      "\n",
      "          29  y_pred  y_test  \n",
      "20   0.14020       1       0  \n",
      "40   0.06165       1       0  \n",
      "42   0.08452       1       0  \n",
      "91   0.09740       1       0  \n",
      "108  0.06829       1       0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#load the breast_cancer dataset\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "#Use dataframe to load the data\n",
    "df = pd.DataFrame(dataset.data)\n",
    "\n",
    "#Define X and y variable\n",
    "X=dataset[\"data\"]\n",
    "y=dataset[\"target\"]\n",
    "\n",
    "#Split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_test, y_test, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Training and testing data\n",
    "print(\"\\n\")\n",
    "print(\"Original data\\n\\n\",df.head(20))\n",
    "print(\"After vectorized train data\\n\\n\",X_train,\"\\n\\n\",y_train)\n",
    "print(\"After vectorized test data\\n\\n\",X_test)\n",
    "\n",
    "#Random Forest Classifier with tuned hyperparameters\n",
    "clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, \n",
    "                             min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
    "                             max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
    "                             bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, \n",
    "                             warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "#fitting the model\n",
    "clf.fit(X_train, y_train)\n",
    "clf.fit(X_test, y_test)\n",
    "clf.fit(X_validation, y_validation)\n",
    "\n",
    "\n",
    "# Predicting the Test, train, and validation results\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred1 = clf.predict(X_train)\n",
    "y_pred2 = clf.predict(X_validation)\n",
    "\n",
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n\",\"Confusion matrix\\n\")\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "#Ploting the heatmap to see the classification of the confusion matrix that predicts true/false for true values and true/false for false values.\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Printing the accuracy values for the testing, training, and validation dataset\n",
    "print(\"\\nClassification report\\n\",metrics.classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy of the testing dataset : \",metrics.accuracy_score(y_test, y_pred)*100)\n",
    "print(\"Accuracy of the training dataset: \",metrics.accuracy_score(y_train, y_pred1)*100)\n",
    "print(\"Accuracy of the validation dataset: \",metrics.accuracy_score(y_validation, y_pred2)*100)\n",
    "\n",
    "#All the incorrect predictions to be shown\n",
    "df2 = pd.DataFrame(X_test)\n",
    "df2['y_pred'] = y_pred\n",
    "df2['y_test'] = y_test\n",
    "df_filtered = df2[(df2['y_pred'] == 0) & (df2['y_test'] == 1)]\n",
    "print(df_filtered)\n",
    "df_filtered2 = df2[(df2['y_pred'] == 1) & (df2['y_test'] == 0)]\n",
    "df_filtered2.head()\n",
    "df_final = pd.concat([df_filtered, df_filtered2])\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Original data\n",
      "\n",
      "        0      1       2       3        4        5        6        7       8   \\\n",
      "0   17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010  0.14710  0.2419   \n",
      "1   20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690  0.07017  0.1812   \n",
      "2   19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740  0.12790  0.2069   \n",
      "3   11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140  0.10520  0.2597   \n",
      "4   20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
      "5   12.45  15.70   82.57   477.1  0.12780  0.17000  0.15780  0.08089  0.2087   \n",
      "6   18.25  19.98  119.60  1040.0  0.09463  0.10900  0.11270  0.07400  0.1794   \n",
      "7   13.71  20.83   90.20   577.9  0.11890  0.16450  0.09366  0.05985  0.2196   \n",
      "8   13.00  21.82   87.50   519.8  0.12730  0.19320  0.18590  0.09353  0.2350   \n",
      "9   12.46  24.04   83.97   475.9  0.11860  0.23960  0.22730  0.08543  0.2030   \n",
      "10  16.02  23.24  102.70   797.8  0.08206  0.06669  0.03299  0.03323  0.1528   \n",
      "11  15.78  17.89  103.60   781.0  0.09710  0.12920  0.09954  0.06606  0.1842   \n",
      "12  19.17  24.80  132.40  1123.0  0.09740  0.24580  0.20650  0.11180  0.2397   \n",
      "13  15.85  23.95  103.70   782.7  0.08401  0.10020  0.09938  0.05364  0.1847   \n",
      "14  13.73  22.61   93.60   578.3  0.11310  0.22930  0.21280  0.08025  0.2069   \n",
      "15  14.54  27.54   96.73   658.8  0.11390  0.15950  0.16390  0.07364  0.2303   \n",
      "16  14.68  20.13   94.74   684.5  0.09867  0.07200  0.07395  0.05259  0.1586   \n",
      "17  16.13  20.68  108.10   798.8  0.11700  0.20220  0.17220  0.10280  0.2164   \n",
      "18  19.81  22.15  130.00  1260.0  0.09831  0.10270  0.14790  0.09498  0.1582   \n",
      "19  13.54  14.36   87.46   566.3  0.09779  0.08129  0.06664  0.04781  0.1885   \n",
      "\n",
      "         9   ...     20     21      22      23      24      25      26  \\\n",
      "0   0.07871  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
      "1   0.05667  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
      "2   0.05999  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
      "3   0.09744  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
      "4   0.05883  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
      "5   0.07613  ...  15.47  23.75  103.40   741.6  0.1791  0.5249  0.5355   \n",
      "6   0.05742  ...  22.88  27.66  153.20  1606.0  0.1442  0.2576  0.3784   \n",
      "7   0.07451  ...  17.06  28.14  110.60   897.0  0.1654  0.3682  0.2678   \n",
      "8   0.07389  ...  15.49  30.73  106.20   739.3  0.1703  0.5401  0.5390   \n",
      "9   0.08243  ...  15.09  40.68   97.65   711.4  0.1853  1.0580  1.1050   \n",
      "10  0.05697  ...  19.19  33.88  123.80  1150.0  0.1181  0.1551  0.1459   \n",
      "11  0.06082  ...  20.42  27.28  136.50  1299.0  0.1396  0.5609  0.3965   \n",
      "12  0.07800  ...  20.96  29.94  151.70  1332.0  0.1037  0.3903  0.3639   \n",
      "13  0.05338  ...  16.84  27.66  112.00   876.5  0.1131  0.1924  0.2322   \n",
      "14  0.07682  ...  15.03  32.01  108.80   697.7  0.1651  0.7725  0.6943   \n",
      "15  0.07077  ...  17.46  37.13  124.10   943.2  0.1678  0.6577  0.7026   \n",
      "16  0.05922  ...  19.07  30.88  123.40  1138.0  0.1464  0.1871  0.2914   \n",
      "17  0.07356  ...  20.96  31.48  136.80  1315.0  0.1789  0.4233  0.4784   \n",
      "18  0.05395  ...  27.32  30.88  186.80  2398.0  0.1512  0.3150  0.5372   \n",
      "19  0.05766  ...  15.11  19.26   99.70   711.2  0.1440  0.1773  0.2390   \n",
      "\n",
      "         27      28       29  \n",
      "0   0.26540  0.4601  0.11890  \n",
      "1   0.18600  0.2750  0.08902  \n",
      "2   0.24300  0.3613  0.08758  \n",
      "3   0.25750  0.6638  0.17300  \n",
      "4   0.16250  0.2364  0.07678  \n",
      "5   0.17410  0.3985  0.12440  \n",
      "6   0.19320  0.3063  0.08368  \n",
      "7   0.15560  0.3196  0.11510  \n",
      "8   0.20600  0.4378  0.10720  \n",
      "9   0.22100  0.4366  0.20750  \n",
      "10  0.09975  0.2948  0.08452  \n",
      "11  0.18100  0.3792  0.10480  \n",
      "12  0.17670  0.3176  0.10230  \n",
      "13  0.11190  0.2809  0.06287  \n",
      "14  0.22080  0.3596  0.14310  \n",
      "15  0.17120  0.4218  0.13410  \n",
      "16  0.16090  0.3029  0.08216  \n",
      "17  0.20730  0.3706  0.11420  \n",
      "18  0.23880  0.2768  0.07615  \n",
      "19  0.12880  0.2977  0.07259  \n",
      "\n",
      "[20 rows x 30 columns]\n",
      "After vectorized train data\n",
      "\n",
      " [[1.917e+01 2.480e+01 1.324e+02 ... 1.767e-01 3.176e-01 1.023e-01]\n",
      " [1.578e+01 2.291e+01 1.057e+02 ... 2.034e-01 3.274e-01 1.252e-01]\n",
      " [7.729e+00 2.549e+01 4.798e+01 ... 0.000e+00 3.058e-01 9.938e-02]\n",
      " ...\n",
      " [1.760e+01 2.333e+01 1.190e+02 ... 1.996e-01 2.301e-01 1.224e-01]\n",
      " [1.403e+01 2.125e+01 8.979e+01 ... 7.963e-02 2.226e-01 7.617e-02]\n",
      " [1.324e+01 2.013e+01 8.687e+01 ... 1.357e-01 2.845e-01 1.249e-01]] \n",
      "\n",
      " [0 0 1 1 1 0 1 0 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 1 1 0 0 1 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0 1 1 0 0\n",
      " 1 1 1 1 0 1 1 1 0 1 1 1 1 0 0 1 1]\n",
      "After vectorized test data\n",
      "\n",
      " [[1.340e+01 2.052e+01 8.864e+01 ... 2.051e-01 3.585e-01 1.109e-01]\n",
      " [1.321e+01 2.525e+01 8.410e+01 ... 6.005e-02 2.444e-01 6.788e-02]\n",
      " [1.402e+01 1.566e+01 8.959e+01 ... 8.216e-02 2.136e-01 6.710e-02]\n",
      " ...\n",
      " [2.018e+01 1.954e+01 1.338e+02 ... 2.173e-01 3.032e-01 8.075e-02]\n",
      " [1.831e+01 2.058e+01 1.208e+02 ... 1.510e-01 3.074e-01 7.863e-02]\n",
      " [1.504e+01 1.674e+01 9.873e+01 ... 1.018e-01 2.177e-01 8.549e-02]]\n",
      "\n",
      " Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        47\n",
      "           1       0.93      0.93      0.93        67\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.91      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "\n",
      "Accuracy of the testing dataset :  91.22807017543859\n",
      "Accuracy of the training dataset:  89.01098901098901\n",
      "Accuracy of the validation dataset:  100.0\n",
      "        0      1      2      3        4       5        6        7       8  \\\n",
      "14  14.64  15.24  95.77  651.9  0.11320  0.1339  0.09966  0.07064  0.2116   \n",
      "44  13.24  20.13  86.87  542.9  0.08284  0.1223  0.10100  0.02833  0.1601   \n",
      "70  14.42  16.54  94.15  641.2  0.09751  0.1139  0.08007  0.04223  0.1912   \n",
      "77  13.05  18.59  85.09  512.0  0.10820  0.1304  0.09603  0.05603  0.2035   \n",
      "92  14.99  22.11  97.53  693.7  0.08515  0.1025  0.06859  0.03876  0.1944   \n",
      "\n",
      "          9  ...      22     23      24      25      26      27      28  \\\n",
      "14  0.06346  ...  109.40  803.6  0.1277  0.3089  0.2604  0.1397  0.3151   \n",
      "44  0.06432  ...  115.00  733.5  0.1201  0.5646  0.6556  0.1357  0.2845   \n",
      "70  0.06412  ...  111.40  862.1  0.1294  0.3371  0.3755  0.1414  0.3053   \n",
      "77  0.06501  ...   94.22  591.2  0.1343  0.2658  0.2573  0.1258  0.3113   \n",
      "92  0.05913  ...  110.20  867.1  0.1077  0.3345  0.3114  0.1308  0.3163   \n",
      "\n",
      "         29  y_pred  y_test  \n",
      "14  0.08473       0       1  \n",
      "44  0.12490       0       1  \n",
      "70  0.08764       0       1  \n",
      "77  0.08317       0       1  \n",
      "92  0.09251       0       1  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "         0      1       2       3        4        5        6        7       8  \\\n",
      "14   14.64  15.24   95.77   651.9  0.11320  0.13390  0.09966  0.07064  0.2116   \n",
      "44   13.24  20.13   86.87   542.9  0.08284  0.12230  0.10100  0.02833  0.1601   \n",
      "70   14.42  16.54   94.15   641.2  0.09751  0.11390  0.08007  0.04223  0.1912   \n",
      "77   13.05  18.59   85.09   512.0  0.10820  0.13040  0.09603  0.05603  0.2035   \n",
      "92   14.99  22.11   97.53   693.7  0.08515  0.10250  0.06859  0.03876  0.1944   \n",
      "37   19.00  18.91  123.40  1138.0  0.08217  0.08028  0.09271  0.05627  0.1946   \n",
      "40   15.13  29.81   96.71   719.5  0.08320  0.04605  0.04686  0.02739  0.1852   \n",
      "42   16.02  23.24  102.70   797.8  0.08206  0.06669  0.03299  0.03323  0.1528   \n",
      "108  15.61  19.38  100.00   758.6  0.07840  0.05616  0.04209  0.02847  0.1547   \n",
      "109  17.42  25.56  114.50   948.0  0.10060  0.11460  0.16820  0.06597  0.1308   \n",
      "\n",
      "           9  ...      22      23      24       25      26       27      28  \\\n",
      "14   0.06346  ...  109.40   803.6  0.1277  0.30890  0.2604  0.13970  0.3151   \n",
      "44   0.06432  ...  115.00   733.5  0.1201  0.56460  0.6556  0.13570  0.2845   \n",
      "70   0.06412  ...  111.40   862.1  0.1294  0.33710  0.3755  0.14140  0.3053   \n",
      "77   0.06501  ...   94.22   591.2  0.1343  0.26580  0.2573  0.12580  0.3113   \n",
      "92   0.05913  ...  110.20   867.1  0.1077  0.33450  0.3114  0.13080  0.3163   \n",
      "37   0.05044  ...  148.20  1538.0  0.1021  0.22640  0.3207  0.12180  0.2841   \n",
      "40   0.05294  ...  110.10   931.4  0.1148  0.09866  0.1547  0.06575  0.3233   \n",
      "42   0.05697  ...  123.80  1150.0  0.1181  0.15510  0.1459  0.09975  0.2948   \n",
      "108  0.05443  ...  115.90   988.6  0.1084  0.18070  0.2260  0.08568  0.2683   \n",
      "109  0.05866  ...  120.40  1021.0  0.1243  0.17930  0.2803  0.10990  0.1603   \n",
      "\n",
      "          29  y_pred  y_test  \n",
      "14   0.08473       0       1  \n",
      "44   0.12490       0       1  \n",
      "70   0.08764       0       1  \n",
      "77   0.08317       0       1  \n",
      "92   0.09251       0       1  \n",
      "37   0.06541       1       0  \n",
      "40   0.06165       1       0  \n",
      "42   0.08452       1       0  \n",
      "108  0.06829       1       0  \n",
      "109  0.06818       1       0  \n",
      "\n",
      "[10 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#load the breast_cancer dataset\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "#Use dataframe to load the data\n",
    "df = pd.DataFrame(dataset.data)\n",
    "\n",
    "#Define X and y variable\n",
    "X=dataset[\"data\"]\n",
    "y=dataset[\"target\"]\n",
    "\n",
    "#Split train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_test, y_test, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Training and testing data\n",
    "print(\"\\n\")\n",
    "print(\"Original data\\n\\n\",df.head(20))\n",
    "print(\"After vectorized train data\\n\\n\",X_train,\"\\n\\n\",y_train)\n",
    "print(\"After vectorized test data\\n\\n\",X_test)\n",
    "\n",
    "#Gradient Boosting Classifier model with tuned hyperparameters\n",
    "clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
    "                                 criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, \n",
    "                                 min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
    "                                 verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, \n",
    "                                 n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "\n",
    "#fitting the model\n",
    "clf.fit(X_train, y_train)\n",
    "clf.fit(X_test, y_test)\n",
    "clf.fit(X_validation, y_validation)\n",
    "\n",
    "\n",
    "# Predicting the Test, train, and validation results\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred1 = clf.predict(X_train)\n",
    "y_pred2 = clf.predict(X_validation)\n",
    "\n",
    "# Creating the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n\",\"Confusion matrix\\n\")\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "\n",
    "#Ploting the heatmap to see the classification of the confusion matrix that predicts true/false for true values and true/false for false values.\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Printing the accuracy values for the testing, training, and validation dataset\n",
    "print(\"\\nClassification report\\n\",metrics.classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy of the testing dataset : \",metrics.accuracy_score(y_test, y_pred)*100)\n",
    "print(\"Accuracy of the training dataset: \",metrics.accuracy_score(y_train, y_pred1)*100)\n",
    "print(\"Accuracy of the validation dataset: \",metrics.accuracy_score(y_validation, y_pred2)*100)\n",
    "\n",
    "#Providing all the incorrect predicted results\n",
    "df2 = pd.DataFrame(X_test)\n",
    "df2['y_pred'] = y_pred\n",
    "df2['y_test'] = y_test\n",
    "df_filtered = df2[(df2['y_pred'] == 0) & (df2['y_test'] == 1)]\n",
    "print(df_filtered)\n",
    "df_filtered2 = df2[(df2['y_pred'] == 1) & (df2['y_test'] == 0)]\n",
    "df_filtered2.head()\n",
    "df_final = pd.concat([df_filtered, df_filtered2])\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
